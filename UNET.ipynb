{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z7JswNTJhfo",
        "outputId": "f8291a8b-8152-47ed-8e4c-d08fba3f7154"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR8x9-8GdVo1",
        "outputId": "d90c095c-92fb-4520-8005-9cb62891a3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1024, 20, 20])\n",
            "torch.Size([3, 512, 40, 40])\n",
            "torch.Size([3, 256, 80, 80])\n",
            "torch.Size([3, 128, 160, 160])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.depht = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.depht(X)\n",
        "\n",
        "class myUNET(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
        "      super(myUNET, self).__init__()\n",
        "      self.encode = nn.ModuleList()\n",
        "      self.decode = nn.ModuleList()\n",
        "      self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #divide size per 2\n",
        "\n",
        "      # Encode\n",
        "      for feature in features:\n",
        "          self.encode.append(DoubleConv(in_channels, feature))\n",
        "          in_channels = feature\n",
        "      \n",
        "      # Decode\n",
        "      for feature in reversed(features):\n",
        "          self.decode.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
        "          self.decode.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "      self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "      self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        #print(X.shape)\n",
        "        skip_connections = []\n",
        "\n",
        "        for depht in self.encode:\n",
        "            X = depht(X)\n",
        "            skip_connections.append(X)\n",
        "            X = self.pool(X)\n",
        "\n",
        "        X = self.bottleneck(X)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for i in range(0, len(self.decode), 2):\n",
        "            X = self.decode[i](X)\n",
        "            #skip_connection = skip_connections[-1 - i//2]\n",
        "            skip_connection = skip_connections[i//2]\n",
        "\n",
        "            if X.shape != skip_connection.shape:\n",
        "                X = torch.nn.functional.interpolate(X, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, X), dim=1)\n",
        "            print(concat_skip.shape)\n",
        "            X = self.decode[i+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(X)\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((3, 1, 160, 160))\n",
        "    m = myUNET(in_channels=1, out_channels=1)\n",
        "    pred = m(x)\n",
        "\n",
        "    assert pred.shape == x.shape\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset_Faces_training.zip\n",
        "!unzip Dataset_Faces_validation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJc3u4Cx6BLa",
        "outputId": "0aadb09a-ef1d-45cf-9243-0b45f0baa06d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Dataset_Faces_training.zip\n",
            "replace Dataset_Faces_training/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  Dataset_Faces_validation.zip\n",
            "replace Dataset_Faces_validation/1000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset_Faces_Mask_training.zip\n",
        "!unzip Dataset_Faces_Mask_validation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpeodVp56gMi",
        "outputId": "8d55e6b5-c11e-4946-bf6c-05091f7cbfae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Dataset_Faces_Mask_training.zip\n",
            "replace Dataset_Faces_Mask_training/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  Dataset_Faces_Mask_validation.zip\n",
            "replace Dataset_Faces_Mask_validation/1000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YPVXNS6mo6mn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uT8RpNPK-vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import (\n",
        "    load_checkpoint,\n",
        "    save_checkpoint,\n",
        "    get_loaders,\n",
        "    check_accuracy,\n",
        "    save_predictions_as_imgs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ouOZHgSC4u5S",
        "outputId": "39f0428d-6d74-4202-8a8a-f73524c2773d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c988103db96c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from utils import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_checkpoint' from 'utils' (/usr/local/lib/python3.10/dist-packages/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamters\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 218\n",
        "IMAGE_WIDTH = 178\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = True\n",
        "IMG_DIR_TRAIN = \"/content/Dataset_Faces_training\"\n",
        "IMG_DIR_VAL = \"/content/Dataset_Faces_validation\"\n",
        "MASK_DIR_TRAIN = \"/content/Dataset_Faces_Mask_training\"\n",
        "MASK_DIR_VAL = \"/content/Dataset_Faces_Mask_validation\""
      ],
      "metadata": {
        "id": "gme7GcrQ4wXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for i_batch, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.floats().unsqueeze(1).to(devide=DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            preds = model(data)\n",
        "            loss = loss_fn(preds, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "3WXnQTla67Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = A.compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.rotate(limit=35, p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.1),\n",
        "        A.Normalize(\n",
        "            mean=[0.0, 0.0, 0.0],\n",
        "            std=[1.0, 1.0, 1.0],\n",
        "            max_pixel_value = 255.0\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "validation_transform = A.compose(\n",
        "    [\n",
        "        A.resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.Normalize(\n",
        "            mean=[0.0, 0.0, 0.0],\n",
        "            std=[1.0, 1.0, 1.0],\n",
        "            max_pixel_value = 255.0\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "UNET = myUNET(in_channels=3, out_channels=1).to(DEVICE) #for multiple classes change out channels to number of classes\n",
        "loss_fn = nn.BCEWithLogitsLoss # for multiple classes use cross entropy\n",
        "optimizer = optim.Adam(UNET.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_loader = get_loaders(\n",
        "    IMG_DIR_TRAIN,\n",
        "    MASK_DIR_TRAIN,\n",
        "    IMG_DIR_VAL,\n",
        "    MASK_DIR_VAL,\n",
        "    BATCH_SIZE,\n",
        "    train_transform,\n",
        "    NUM_WORKERS,\n",
        "    PIN_MEMORY\n",
        ")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train(train_loader, UNET, optimizer, loss_fn, scaler)"
      ],
      "metadata": {
        "id": "DAAUW9kb9YqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}